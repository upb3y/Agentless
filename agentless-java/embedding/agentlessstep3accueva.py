# -*- coding: utf-8 -*-
"""AgentlessStep3AccuEva.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rHNrd-MXXH2HkKSi-LsLgrAoPhdwypwL
"""

import json
import os
from typing import List, Dict, Any, Tuple

def calculate_localization_accuracy(suspicious_files_path: str,
                                    ground_truth_path: str) -> Tuple[float, float]:
    """
    Calculate the accuracy of suspicious files predictions compared to ground truth.

    Args:
        suspicious_files_path (str): Path to the JSON file containing suspicious files predictions.
        ground_truth_path (str): Path to the JSON file containing ground truth data.

    Returns:
        Tuple[float, float]: A tuple containing (superset_accuracy, touch_accuracy)
    """
    # Load the suspicious files predictions
    with open(suspicious_files_path, 'r') as f:
        suspicious_files = json.load(f)

    # Load the ground truth data
    with open(ground_truth_path, 'r') as f:
        ground_truth = json.load(f)

    # Create a mapping from instance_id to ground truth files
    ground_truth_map = {item["instance_id"]: set(item["modified_files"]) for item in ground_truth}

    total_instances = 0
    superset_count = 0
    touch_count = 0

    # Process each suspicious files prediction
    for prediction in suspicious_files:
        instance_id = prediction["instance_id"]
        if instance_id in ground_truth_map:
            total_instances += 1
            predicted_files = set(prediction["suspicious_files"])
            ground_truth_files = ground_truth_map[instance_id]

            # Check if predicted files are a superset of ground truth files
            if ground_truth_files.issubset(predicted_files):
                superset_count += 1

            # Check if there's at least one overlap between predicted and ground truth files
            if len(ground_truth_files.intersection(predicted_files)) > 0:
                touch_count += 1

    # Calculate accuracies
    print("Total instances:", total_instances)
    print("Superset count:", superset_count)
    superset_accuracy = superset_count / total_instances if total_instances > 0 else 0.0
    touch_accuracy = touch_count / total_instances if total_instances > 0 else 0.0

    return superset_accuracy, touch_accuracy

def calculate_intersect_localization_accuracy(suspicious_files_path1: str,
                                    suspicious_files_path2: str,
                                    ground_truth_path: str) -> Tuple[float, float]:
    """
    Calculate the accuracy of suspicious files predictions compared to ground truth.

    Args:
        suspicious_files_path (str): Path to the JSON file containing suspicious files predictions.
        ground_truth_path (str): Path to the JSON file containing ground truth data.

    Returns:
        Tuple[float, float]: A tuple containing (superset_accuracy, touch_accuracy)
    """
    # Load the suspicious files predictions
    with open(suspicious_files_path1, 'r') as f:
        suspicious_files1 = json.load(f)
    with open(suspicious_files_path2, 'r') as f:
        suspicious_files2 = json.load(f)

    # Load the ground truth data
    with open(ground_truth_path, 'r') as f:
        ground_truth = json.load(f)

    # Create a mapping from instance_id to ground truth files
    ground_truth_map = {item["instance_id"]: set(item["modified_files"]) for item in ground_truth}

    total_instances = 0
    superset_count = 0
    touch_count = 0

    # Process each suspicious files prediction
    for i in range(len(suspicious_files1)):
        prediction1 = suspicious_files1[i]
        prediction2 = suspicious_files2[i]
        instance_id = prediction1["instance_id"]
        if instance_id in ground_truth_map:
            total_instances += 1
            predicted_files = set(prediction1["suspicious_files"]).intersect(set(prediction2["suspicious_files"]))
            ground_truth_files = ground_truth_map[instance_id]

            # Check if predicted files are a superset of ground truth files
            if ground_truth_files.issubset(predicted_files):
                superset_count += 1

            # Check if there's at least one overlap between predicted and ground truth files
            if len(ground_truth_files.intersection(predicted_files)) > 0:
                touch_count += 1

    # Calculate accuracies
    print("Total instances:", total_instances)
    print("Superset count:", superset_count)
    superset_accuracy = superset_count / total_instances if total_instances > 0 else 0.0
    touch_accuracy = touch_count / total_instances if total_instances > 0 else 0.0

    return superset_accuracy, touch_accuracy

def run_evaluation():
    # Paths to your files
    suspicious_files_path1 = "/content/suspicious_files.json"
    suspicious_files_path2 = "/content/suspicious_files_results (1).json"  # Path to your suspicious files predictions
    ground_truth_path = "/content/ground_truth.json"          # Path to ground truth data

    if os.path.exists(suspicious_files_path1) and os.path.exists(ground_truth_path):
        superset_accuracy, touch_accuracy = calculate_union_localization_accuracy(
            suspicious_files_path1, suspicious_files_path2, ground_truth_path
        )

        print(f"Evaluation Results:")
        print(f"- Superset Accuracy: {superset_accuracy:.4f} ({superset_accuracy*100:.2f}%)")
        print(f"- Touch Accuracy:    {touch_accuracy:.4f} ({touch_accuracy*100:.2f}%)")

run_evaluation()

# Let's run the Python snippet to merge the two JSON files and save the output as a downloadable file.

import json

# Load both JSON files from the mounted directory
with open("/content/suspicious_files.json", "r") as f:
    data1 = json.load(f)
with open("/content/suspicious_files_results (1).json", "r") as f:
    data2 = json.load(f)

merged = {}
for entry in data1 + data2:
    key = (entry["repo"], entry["instance_id"])
    if key not in merged:
        merged[key] = {
            "repo": entry["repo"],
            "instance_id": entry["instance_id"],
            "suspicious_files": []
        }
    merged[key]["suspicious_files"].extend(entry["suspicious_files"])

# Remove duplicate file entries
for entry in merged.values():
    entry["suspicious_files"] = list(dict.fromkeys(entry["suspicious_files"]))

combined = list(merged.values())

# Write the merged output to a file
output_path = "/content/merged_suspicious_files.json"
with open(output_path, "w") as f:
    json.dump(combined, f, indent=2)

print("Merged file saved at:", output_path)

def run_evaluation():
    # Paths to your files
    suspicious_files_path = "/content/merged_suspicious_files.json"  # Path to your suspicious files predictions
    ground_truth_path = "/content/ground_truth.json"          # Path to ground truth data

    if os.path.exists(suspicious_files_path) and os.path.exists(ground_truth_path):
        superset_accuracy, touch_accuracy = calculate_localization_accuracy(
            suspicious_files_path, ground_truth_path
        )

        print(f"Evaluation Results:")
        print(f"- Superset Accuracy: {superset_accuracy:.4f} ({superset_accuracy*100:.2f}%)")
        print(f"- Touch Accuracy:    {touch_accuracy:.4f} ({touch_accuracy*100:.2f}%)")
    else:
        print(f"Error: One or both of the input files do not exist.")
        print(f"  - Suspicious files path: {os.path.exists(suspicious_files_path)}")
        print(f"  - Ground truth path: {os.path.exists(ground_truth_path)}")

run_evaluation()

